{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f39e557f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets try doing all this in pytoooorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "009b1c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "from source import Dataset as ds\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "176a61d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "``/nfs/dust/cms/user/loewetob/ML_LLP/MDS_regression/datasets`` does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_68384/2080944607.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m#read data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mdataset_signal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"signal\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mdf_signal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_signal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/nfs/dust/cms/user/loewetob/ML_LLP/MDS_regression/datasets/test_df_v6.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m#cut clusters which don't have LLP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MDS_regression/source/Dataset.py\u001b[0m in \u001b[0;36mload_df\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;31m# load pandas df from h5 file and store it in class variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0mstore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHDFStore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;31m#if store.keys() ==[]:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0;31m#    print(\"Warning, empty dataframe, skipping...\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mds_regression_cpu2/lib/python3.7/site-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode, complevel, complib, fletcher32, **kwargs)\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fletcher32\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfletcher32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mds_regression_cpu2/lib/python3.7/site-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mds_regression_cpu2/lib/python3.7/site-packages/tables/file.py\u001b[0m in \u001b[0;36mopen_file\u001b[0;34m(filename, mode, title, root_uep, filters, **kwargs)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;31m# Finally, create the File instance, and return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_uep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mds_regression_cpu2/lib/python3.7/site-packages/tables/file.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, title, root_uep, filters, **kwargs)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0;31m# Now, it is time to initialize the File extension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_g_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;31m# Check filters and set PyTables format version for new files.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mds_regression_cpu2/lib/python3.7/site-packages/tables/hdf5extension.pyx\u001b[0m in \u001b[0;36mtables.hdf5extension.File._g_new\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mds_regression_cpu2/lib/python3.7/site-packages/tables/utils.py\u001b[0m in \u001b[0;36mcheck_file_access\u001b[0;34m(filename, mode)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mcheck_file_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0mcheck_file_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mcheck_file_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mds_regression_cpu2/lib/python3.7/site-packages/tables/utils.py\u001b[0m in \u001b[0;36mcheck_file_access\u001b[0;34m(filename, mode)\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;31m# so the directory should be writable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mF_OK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"``{path.parent}`` does not exist\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"``{path.parent}`` is not a directory\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: ``/nfs/dust/cms/user/loewetob/ML_LLP/MDS_regression/datasets`` does not exist"
     ]
    }
   ],
   "source": [
    "#selecting features \n",
    "branches_to_use = [\n",
    "\"cscRechitClusterX\",\n",
    "\"cscRechitClusterY\",\n",
    "\"cscRechitClusterZ\",\n",
    "\"cscRechitClusterTimeWeighted\",\n",
    "\"cscRechitClusterTimeSpreadWeightedAll\",\n",
    "\"cscRechitClusternXY\",\n",
    "\"cscRechitClusternZ\",\n",
    "\"cscRechitClusterXSpread\",\n",
    "\"cscRechitClusterYSpread\",\n",
    "\"cscRechitClusterZSpread\",\n",
    "\"cscRechitClusterXYSpread\",\n",
    "\"cscRechitClusterRSpread\",\n",
    "\"cscRechitClusterEtaPhiSpread\",\n",
    "\"cscRechitClusterEtaSpread\",\n",
    "\"cscRechitClusterPhiSpread\",\n",
    "\"cscRechitClusterDeltaRSpread\",\n",
    "\"cscRechitClusterMajorAxis\",\n",
    "\"cscRechitClusterMinorAxis\",\n",
    "\"cscRechitClusterSkewX\",\n",
    "\"cscRechitClusterSkewY\",\n",
    "\"cscRechitClusterSkewZ\",\n",
    "\"cscRechitClusterKurtX\",\n",
    "\"cscRechitClusterKurtY\",\n",
    "\"cscRechitClusterKurtZ\", \n",
    "\"cscRechitClusterSize\",\n",
    "\"cscRechitCluster_match_gLLP_e\"\n",
    "]\n",
    "\n",
    "#energy key\n",
    "truth_value = \"cscRechitCluster_match_gLLP_e\"\n",
    "size_value = \"cscRechitClusterSize\"\n",
    "\n",
    "#read data\n",
    "dataset_signal = ds.Dataset(\"signal\")\n",
    "df_signal = dataset_signal.load_df(\"/nfs/dust/cms/user/loewetob/ML_LLP/MDS_regression/datasets/test_df_v6.h5\")\n",
    "\n",
    "#cut clusters which don't have LLP\n",
    "olen = len(df_signal)\n",
    "df_signal = df_signal[ df_signal[\"cscRechitCluster_match_gLLP\"]>=1 ]\n",
    "print('cut out ' + str(olen - len(df_signal)) + ' clusters, which leaves ' + str(len(df_signal)) + ' clusters containing a LLP decay for training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7bc549",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mdsDataset(Dataset):\n",
    "    def __init__(self, dataframe, feature_keys = branches_to_use[:-1], label_key = branches_to_use[-1]):\n",
    "        self.dataframe = dataframe\n",
    "        self.feature_keys = feature_keys\n",
    "        self.label_key = label_key\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = {\n",
    "            'features': torch.tensor(self.dataframe.iloc[idx][self.feature_keys].tolist(), dtype=torch.float32),\n",
    "            'label': torch.tensor(self.dataframe.iloc[idx][self.label_key], dtype=torch.float32).squeeze()\n",
    "        }\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a69d16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, input_size, layers = [50, 30, 20, 5, 1]):\n",
    "        super(MyModel, self).__init__()\n",
    "        \n",
    "        self.fc_layers = nn.ModuleList()  # ModuleList to hold dynamically created layers\n",
    "        \n",
    "        # first layer\n",
    "        self.fc_layers.append(nn.Linear(input_size, layers[0]))\n",
    "        self.fc_layers.append(nn.ReLU())\n",
    "        \n",
    "        # other layers\n",
    "        for i in range(len(layers) - 1):\n",
    "            self.fc_layers.append(nn.Linear(layers[i], layers[i + 1]))\n",
    "            self.fc_layers.append(nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.fc_layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0283cd49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = MyModel(input_size=25)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53871c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, testval_data = train_test_split(df_signal, train_size=0.6)\n",
    "test_data, val_data = train_test_split(testval_data, test_size=0.5)\n",
    "\n",
    "batch_size = 2048\n",
    "\n",
    "train_dataset = mdsDataset(dataframe = train_data)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_dataset = mdsDataset(dataframe = val_data)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataset = mdsDataset(dataframe = test_data)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9db52150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH0\n",
      "train loss 29620.509765625\n",
      "train loss 28364.580078125\n",
      "train loss 27503.787109375\n",
      "train loss 23455.439453125\n",
      "train loss 18754.05859375\n",
      "train loss 13111.4140625\n",
      "train loss 7693.14599609375\n",
      "train loss 10921.6328125\n",
      "train loss 12918.53125\n",
      "train loss 10440.205078125\n",
      "train loss 8006.73779296875\n",
      "train loss 7777.0791015625\n",
      "train loss 7619.8056640625\n",
      "train loss 8544.779296875\n",
      "train loss 9624.9140625\n",
      "train loss 8220.8798828125\n",
      "train loss 9226.6513671875\n",
      "train loss 7170.88134765625\n",
      "train loss 6426.58447265625\n",
      "train loss 7149.3701171875\n",
      "train loss 7645.49267578125\n",
      "train loss 7784.98876953125\n",
      "train loss 7121.0732421875\n",
      "train loss 8344.49609375\n",
      "val loss tensor(5882.6455)\n",
      "val loss tensor(6003.6870)\n",
      "val loss tensor(7526.7095)\n",
      "val loss tensor(5391.0430)\n",
      "val loss tensor(7086.5034)\n",
      "val loss tensor(7623.7139)\n",
      "val loss tensor(5652.1396)\n",
      "val loss tensor(7249.8989)\n",
      "EPOCH1\n",
      "train loss 5941.71533203125\n",
      "train loss 5754.3359375\n",
      "train loss 6579.876953125\n",
      "train loss 6641.2724609375\n",
      "train loss 6362.82373046875\n",
      "train loss 6230.63671875\n",
      "train loss 5640.6591796875\n",
      "train loss 6530.50439453125\n",
      "train loss 6781.7392578125\n",
      "train loss 6619.61328125\n",
      "train loss 7025.681640625\n",
      "train loss 7288.12744140625\n",
      "train loss 6312.978515625\n",
      "train loss 6724.140625\n",
      "train loss 7282.73974609375\n",
      "train loss 6527.68994140625\n",
      "train loss 7857.29296875\n",
      "train loss 6720.55517578125\n",
      "train loss 6194.64501953125\n",
      "train loss 6465.587890625\n",
      "train loss 6349.669921875\n",
      "train loss 6554.63232421875\n",
      "train loss 6386.96484375\n",
      "train loss 7876.9111328125\n",
      "val loss tensor(5554.3413)\n",
      "val loss tensor(5778.5747)\n",
      "val loss tensor(7262.2607)\n",
      "val loss tensor(5213.0654)\n",
      "val loss tensor(6732.6357)\n",
      "val loss tensor(7307.6538)\n",
      "val loss tensor(5389.6294)\n",
      "val loss tensor(6987.5020)\n",
      "EPOCH2\n",
      "train loss 5787.689453125\n",
      "train loss 5359.048828125\n",
      "train loss 5888.83447265625\n",
      "train loss 5988.859375\n",
      "train loss 5804.45166015625\n",
      "train loss 5901.529296875\n",
      "train loss 5514.0419921875\n",
      "train loss 6409.296875\n",
      "train loss 6612.7470703125\n",
      "train loss 6263.5234375\n",
      "train loss 6687.55224609375\n",
      "train loss 7048.005859375\n",
      "train loss 6154.3271484375\n",
      "train loss 6616.083984375\n",
      "train loss 7075.48486328125\n",
      "train loss 6299.603515625\n",
      "train loss 7471.04150390625\n",
      "train loss 6468.80322265625\n",
      "train loss 6065.72607421875\n",
      "train loss 6389.78515625\n",
      "train loss 6253.35888671875\n",
      "train loss 6375.46630859375\n",
      "train loss 6178.568359375\n",
      "train loss 7764.08251953125\n",
      "val loss tensor(5453.0645)\n",
      "val loss tensor(5648.7905)\n",
      "val loss tensor(7162.8843)\n",
      "val loss tensor(5064.4868)\n",
      "val loss tensor(6631.4019)\n",
      "val loss tensor(7229.5786)\n",
      "val loss tensor(5259.6709)\n",
      "val loss tensor(6883.1714)\n",
      "EPOCH3\n",
      "train loss 5645.134765625\n",
      "train loss 5261.1103515625\n",
      "train loss 5784.39892578125\n",
      "train loss 5848.83837890625\n",
      "train loss 5651.474609375\n",
      "train loss 5754.08251953125\n",
      "train loss 5438.849609375\n",
      "train loss 6321.89208984375\n",
      "train loss 6494.7900390625\n",
      "train loss 6121.828125\n",
      "train loss 6555.10107421875\n",
      "train loss 6912.2802734375\n",
      "train loss 6025.2666015625\n",
      "train loss 6501.59326171875\n",
      "train loss 6945.126953125\n",
      "train loss 6158.76708984375\n",
      "train loss 7275.91796875\n",
      "train loss 6352.15869140625\n",
      "train loss 5981.970703125\n",
      "train loss 6272.66796875\n",
      "train loss 6121.38818359375\n",
      "train loss 6217.6201171875\n",
      "train loss 6047.7919921875\n",
      "train loss 7693.32177734375\n",
      "val loss tensor(5362.5278)\n",
      "val loss tensor(5555.5312)\n",
      "val loss tensor(7045.1367)\n",
      "val loss tensor(4964.0210)\n",
      "val loss tensor(6523.2568)\n",
      "val loss tensor(7130.8462)\n",
      "val loss tensor(5153.5542)\n",
      "val loss tensor(6773.5469)\n",
      "EPOCH4\n",
      "train loss 5561.30810546875\n",
      "train loss 5139.6552734375\n",
      "train loss 5648.3720703125\n",
      "train loss 5730.3935546875\n",
      "train loss 5566.1826171875\n",
      "train loss 5632.14013671875\n",
      "train loss 5337.4189453125\n",
      "train loss 6200.8623046875\n",
      "train loss 6389.634765625\n",
      "train loss 6004.9716796875\n",
      "train loss 6417.8466796875\n",
      "train loss 6813.0380859375\n",
      "train loss 5889.298828125\n",
      "train loss 6404.31787109375\n",
      "train loss 6797.20361328125\n",
      "train loss 5999.39208984375\n",
      "train loss 7177.39208984375\n",
      "train loss 6228.857421875\n",
      "train loss 5882.6572265625\n",
      "train loss 6154.220703125\n",
      "train loss 6018.751953125\n",
      "train loss 6071.82666015625\n",
      "train loss 5926.76904296875\n",
      "train loss 7570.36328125\n",
      "val loss tensor(5255.8511)\n",
      "val loss tensor(5458.5024)\n",
      "val loss tensor(6902.1050)\n",
      "val loss tensor(4848.9766)\n",
      "val loss tensor(6403.4326)\n",
      "val loss tensor(7007.6616)\n",
      "val loss tensor(5033.1133)\n",
      "val loss tensor(6654.7646)\n",
      "EPOCH5\n",
      "train loss 5479.2041015625\n",
      "train loss 5016.560546875\n",
      "train loss 5533.060546875\n",
      "train loss 5605.3447265625\n",
      "train loss 5442.8583984375\n",
      "train loss 5496.48876953125\n",
      "train loss 5194.890625\n",
      "train loss 6032.25\n",
      "train loss 6204.8740234375\n",
      "train loss 5831.79541015625\n",
      "train loss 6215.9951171875\n",
      "train loss 6639.7451171875\n",
      "train loss 5659.357421875\n",
      "train loss 6166.11669921875\n",
      "train loss 6553.7392578125\n",
      "train loss 5737.287109375\n",
      "train loss 6898.39697265625\n",
      "train loss 5929.86083984375\n",
      "train loss 5628.18408203125\n",
      "train loss 5915.232421875\n",
      "train loss 5758.88232421875\n",
      "train loss 5760.501953125\n",
      "train loss 5626.0126953125\n",
      "train loss 7141.705078125\n",
      "val loss tensor(5018.5371)\n",
      "val loss tensor(5186.3916)\n",
      "val loss tensor(6507.2256)\n",
      "val loss tensor(4573.5430)\n",
      "val loss tensor(6128.5645)\n",
      "val loss tensor(6701.9180)\n",
      "val loss tensor(4754.9033)\n",
      "val loss tensor(6355.6699)\n",
      "EPOCH6\n",
      "train loss 5232.04052734375\n",
      "train loss 4753.2978515625\n",
      "train loss 5231.50732421875\n",
      "train loss 5324.08984375\n",
      "train loss 5200.71875\n",
      "train loss 5260.60986328125\n",
      "train loss 4948.462890625\n",
      "train loss 5734.5849609375\n",
      "train loss 5903.3095703125\n",
      "train loss 5628.9072265625\n",
      "train loss 6014.96826171875\n",
      "train loss 6450.0810546875\n",
      "train loss 5410.22021484375\n",
      "train loss 5987.35595703125\n",
      "train loss 6346.3232421875\n",
      "train loss 5528.73876953125\n",
      "train loss 6647.7021484375\n",
      "train loss 5751.1875\n",
      "train loss 5472.19677734375\n",
      "train loss 5787.10595703125\n",
      "train loss 5668.3642578125\n",
      "train loss 5656.2158203125\n",
      "train loss 5542.35546875\n",
      "train loss 6908.6923828125\n",
      "val loss tensor(5033.0708)\n",
      "val loss tensor(5167.3779)\n",
      "val loss tensor(6405.3110)\n",
      "val loss tensor(4535.2690)\n",
      "val loss tensor(6108.6709)\n",
      "val loss tensor(6626.2285)\n",
      "val loss tensor(4708.2314)\n",
      "val loss tensor(6277.4854)\n",
      "EPOCH7\n",
      "train loss 5188.9228515625\n",
      "train loss 4661.48388671875\n",
      "train loss 5191.759765625\n",
      "train loss 5292.44580078125\n",
      "train loss 5152.8037109375\n",
      "train loss 5217.34912109375\n",
      "train loss 4947.58349609375\n",
      "train loss 5654.0009765625\n",
      "train loss 5842.16259765625\n",
      "train loss 5596.830078125\n",
      "train loss 5959.51025390625\n",
      "train loss 6394.83154296875\n",
      "train loss 5349.126953125\n",
      "train loss 5922.25341796875\n",
      "train loss 6278.7724609375\n",
      "train loss 5482.33447265625\n",
      "train loss 6601.9267578125\n",
      "train loss 5658.201171875\n",
      "train loss 5464.15771484375\n",
      "train loss 5743.740234375\n",
      "train loss 5611.958984375\n",
      "train loss 5618.52734375\n",
      "train loss 5522.564453125\n",
      "train loss 6841.38330078125\n",
      "val loss tensor(4990.1992)\n",
      "val loss tensor(5104.6978)\n",
      "val loss tensor(6362.9902)\n",
      "val loss tensor(4480.0703)\n",
      "val loss tensor(6062.9102)\n",
      "val loss tensor(6571.3926)\n",
      "val loss tensor(4652.7827)\n",
      "val loss tensor(6237.8140)\n",
      "EPOCH8\n",
      "train loss 5139.7763671875\n",
      "train loss 4649.71923828125\n",
      "train loss 5136.125\n",
      "train loss 5266.4951171875\n",
      "train loss 5128.359375\n",
      "train loss 5175.65478515625\n",
      "train loss 4884.70556640625\n",
      "train loss 5611.5068359375\n",
      "train loss 5802.68017578125\n",
      "train loss 5552.36669921875\n",
      "train loss 5912.73193359375\n",
      "train loss 6351.69677734375\n",
      "train loss 5298.96044921875\n",
      "train loss 5883.38720703125\n",
      "train loss 6244.345703125\n",
      "train loss 5449.86669921875\n",
      "train loss 6550.154296875\n",
      "train loss 5631.1826171875\n",
      "train loss 5420.47265625\n",
      "train loss 5692.740234375\n",
      "train loss 5582.548828125\n",
      "train loss 5594.4423828125\n",
      "train loss 5484.49560546875\n",
      "train loss 6761.7265625\n",
      "val loss tensor(4972.9219)\n",
      "val loss tensor(5088.3188)\n",
      "val loss tensor(6341.1279)\n",
      "val loss tensor(4458.6074)\n",
      "val loss tensor(6046.3521)\n",
      "val loss tensor(6552.1372)\n",
      "val loss tensor(4625.7842)\n",
      "val loss tensor(6236.8193)\n",
      "EPOCH9\n",
      "train loss 5119.875\n",
      "train loss 4622.865234375\n",
      "train loss 5128.49951171875\n",
      "train loss 5249.79052734375\n",
      "train loss 5094.41162109375\n",
      "train loss 5159.48046875\n",
      "train loss 4855.01611328125\n",
      "train loss 5572.5986328125\n",
      "train loss 5766.853515625\n",
      "train loss 5565.8232421875\n",
      "train loss 5896.56396484375\n",
      "train loss 6315.34619140625\n",
      "train loss 5284.294921875\n",
      "train loss 5850.53759765625\n",
      "train loss 6194.13720703125\n",
      "train loss 5425.71484375\n",
      "train loss 6523.70458984375\n",
      "train loss 5601.58642578125\n",
      "train loss 5384.61181640625\n",
      "train loss 5667.2607421875\n",
      "train loss 5598.47607421875\n",
      "train loss 5566.00927734375\n",
      "train loss 5479.7294921875\n",
      "train loss 6742.05712890625\n",
      "val loss tensor(4951.4141)\n",
      "val loss tensor(5068.4082)\n",
      "val loss tensor(6333.8779)\n",
      "val loss tensor(4398.7402)\n",
      "val loss tensor(6026.4043)\n",
      "val loss tensor(6532.6479)\n",
      "val loss tensor(4599.0146)\n",
      "val loss tensor(6216.5552)\n",
      "best val losstensor(6216.5552)\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float('inf')\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training loop\n",
    "    print('EPOCH' + str(epoch))\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        inputs = batch['features']\n",
    "        labels = batch['label']\n",
    "        optimizer.zero_grad()\n",
    "        outputs = torch.flatten(model(inputs))\n",
    "        loss = criterion(outputs, labels)\n",
    "        print('train loss ' + str(loss.item()))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            inputs = batch['features']\n",
    "            labels = batch['label']\n",
    "            outputs = torch.flatten(model(inputs))\n",
    "            val_loss = criterion(outputs, labels)\n",
    "            print('val loss ' + str(val_loss.item()))\n",
    "            # Calculate additional validation metrics if needed\n",
    "\n",
    "            # Save the model if it has the best validation loss\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                torch.save(model.state_dict(), 'best_model.pth')\n",
    "print('best val loss' + str(best_val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66f9a889",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_plot(pred, test_labels, title = None, axlabels = ('clusters', 'generated particle energy')):\n",
    "    fig, ax = plt.subplots(figsize = (6, 4))\n",
    "    \n",
    "    histdata, bins, dummy = ax.hist(test_labels, bins = 50, histtype=\"step\", color = 'b', label = 'truth')\n",
    "    ax.hist(pred, bins = bins, histtype=\"step\", color = 'r', label = 'predictions')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylabel(axlabels[0])\n",
    "    ax.set_xlabel(axlabels[1])\n",
    "    ax.legend()\n",
    "    if title:\n",
    "        ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b8c9c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "labels = []\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        inputs = batch['features']\n",
    "        label = batch['label']\n",
    "        prediction = torch.flatten(model(inputs))\n",
    "        predictions.append(prediction)\n",
    "        labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7580d9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = [tensor.item() for tensor in predictions]\n",
    "l = [tensor.item() for tensor in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ca184bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict_plot(p, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1b26da-2d91-4e3a-a034-b6dc04decbda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mds_regression2",
   "language": "python",
   "name": "mds_regression2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
