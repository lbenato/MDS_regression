{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "518b750a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-11 15:25:44.913070: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-11 15:25:45.067574: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-12-11 15:25:45.067611: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-12-11 15:25:46.401700: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-12-11 15:25:46.401826: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-12-11 15:25:46.401840: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-12-11 15:25:49.906234: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-12-11 15:25:49.906271: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-12-11 15:25:49.906298: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (batch1174.desy.de): /proc/driver/nvidia/version does not exist\n",
      "2023-12-11 15:25:49.906574: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from source import Dataset\n",
    "from source import tools\n",
    "import awkward as ak\n",
    "import glob\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import optimizers\n",
    "from keras import layers\n",
    "\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17ff7cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting features \n",
    "branches_to_train = [\n",
    "\"cscRechitClusterX\",\n",
    "\"cscRechitClusterY\",\n",
    "\"cscRechitClusterZ\",\n",
    "\"cscRechitClusterTimeWeighted\",\n",
    "\"cscRechitClusterTimeSpreadWeightedAll\",\n",
    "\"cscRechitClusternXY\",\n",
    "\"cscRechitClusternZ\",\n",
    "\"cscRechitClusterXSpread\",\n",
    "\"cscRechitClusterYSpread\",\n",
    "\"cscRechitClusterZSpread\",\n",
    "\"cscRechitClusterXYSpread\",\n",
    "\"cscRechitClusterRSpread\",\n",
    "\"cscRechitClusterEtaPhiSpread\",\n",
    "\"cscRechitClusterEtaSpread\",\n",
    "\"cscRechitClusterPhiSpread\",\n",
    "\"cscRechitClusterDeltaRSpread\",\n",
    "\"cscRechitClusterMajorAxis\",\n",
    "\"cscRechitClusterMinorAxis\",\n",
    "\"cscRechitClusterSkewX\",\n",
    "\"cscRechitClusterSkewY\",\n",
    "\"cscRechitClusterSkewZ\",\n",
    "\"cscRechitClusterKurtX\",\n",
    "\"cscRechitClusterKurtY\",\n",
    "\"cscRechitClusterKurtZ\", \n",
    "\"cscRechitClusterSize\"\n",
    "]\n",
    "\n",
    "#energy key\n",
    "truth_value = \"cscRechitCluster_match_gLLP_e\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbaaf2aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cscRechitClusterX',\n",
       " 'cscRechitClusterY',\n",
       " 'cscRechitClusterZ',\n",
       " 'cscRechitClusterTimeWeighted',\n",
       " 'cscRechitClusterTimeSpreadWeightedAll',\n",
       " 'cscRechitClusternXY',\n",
       " 'cscRechitClusternZ',\n",
       " 'cscRechitClusterXSpread',\n",
       " 'cscRechitClusterYSpread',\n",
       " 'cscRechitClusterZSpread',\n",
       " 'cscRechitClusterXYSpread',\n",
       " 'cscRechitClusterRSpread',\n",
       " 'cscRechitClusterEtaPhiSpread',\n",
       " 'cscRechitClusterEtaSpread',\n",
       " 'cscRechitClusterPhiSpread',\n",
       " 'cscRechitClusterDeltaRSpread',\n",
       " 'cscRechitClusterMajorAxis',\n",
       " 'cscRechitClusterMinorAxis',\n",
       " 'cscRechitClusterSkewX',\n",
       " 'cscRechitClusterSkewY',\n",
       " 'cscRechitClusterSkewZ',\n",
       " 'cscRechitClusterKurtX',\n",
       " 'cscRechitClusterKurtY',\n",
       " 'cscRechitClusterKurtZ',\n",
       " 'cscRechitClusterSize']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "branches_to_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9492f9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening file  /nfs/dust/cms/user/loewetob/ML_LLP/MDS_regression/datasets/test_bigger_dataset.h5\n"
     ]
    }
   ],
   "source": [
    "#read data\n",
    "dataset_signal = Dataset.Dataset(\"signal\")\n",
    "df_signal = dataset_signal.load_df(\"/nfs/dust/cms/user/loewetob/ML_LLP/MDS_regression/datasets/test_bigger_dataset.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b7b4c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cut out 10236 clusters, which leaves 344078 clusters containing a LLP decay for training\n"
     ]
    }
   ],
   "source": [
    "#cut clusters which don't have LLP\n",
    "olen = len(df_signal)\n",
    "df_signal = df_signal[ df_signal[\"cscRechitCluster_match_gLLP\"]>=1 ]\n",
    "print('cut out ' + str(olen - len(df_signal)) + ' clusters, which leaves ' + str(len(df_signal)) + ' clusters containing a LLP decay for training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e04220a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " signal training features (206446, 25) \n",
      " signal training labels (206446,) \n",
      " signal test features (68816, 25) \n",
      " ignal test labels (68816,) \n",
      " signal val features (68816, 25) \n",
      " signal val labels (68816,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into train, val, test\n",
    "train_data, testval_data = train_test_split(df_signal, train_size=0.6)\n",
    "test_data, val_data = train_test_split(testval_data, test_size=0.5)\n",
    "\n",
    "# assigning labels (true energy values)\n",
    "train_labels = np.array(train_data[truth_value])#([1.]*len(train_data))\n",
    "test_labels = np.array(test_data[truth_value])#([1.]*len(test_data))\n",
    "val_labels = np.array(val_data[truth_value])#([1.]*len(val_data))\n",
    "\n",
    "# select only branches we want\n",
    "train_data = train_data[branches_to_train]\n",
    "test_data = test_data[branches_to_train]\n",
    "val_data = val_data[branches_to_train]\n",
    "\n",
    "# check the shape\n",
    "print(\" signal training features\", train_data.shape,\n",
    "    \"\\n signal training labels\", train_labels.shape,\n",
    "    \"\\n signal test features\", test_data.shape,\n",
    "    \"\\n ignal test labels\", test_labels.shape,\n",
    "    \"\\n signal val features\", val_data.shape,\n",
    "    \"\\n signal val labels\", val_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a68b7feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[191.20671082 195.83912659  49.03752518 ...  99.17763519 111.77108002\n",
      " 109.3277359 ]\n",
      "        cscRechitClusterX  cscRechitClusterY  cscRechitClusterZ  \\\n",
      "entry                                                             \n",
      "135442          75.217720         180.255081         971.266479   \n",
      "311313         -13.523779        -122.013863         602.904175   \n",
      "319843         -88.876160         377.135590         703.310547   \n",
      "96990          201.698593         361.727386         729.699890   \n",
      "133156         214.046646        -304.128204        -961.758484   \n",
      "...                   ...                ...                ...   \n",
      "129493         147.595016         -57.798214         609.018005   \n",
      "85410         -164.670822         188.651611        -975.440063   \n",
      "239343         375.876038         385.332214         693.842712   \n",
      "66571          325.425323         -87.935844         693.664917   \n",
      "352243         355.241699        -253.019958        -836.984314   \n",
      "\n",
      "        cscRechitClusterTimeWeighted  cscRechitClusterTimeSpreadWeightedAll  \\\n",
      "entry                                                                         \n",
      "135442                      0.275838                              11.866124   \n",
      "311313                     -0.400750                               7.764334   \n",
      "319843                      1.608885                              12.703094   \n",
      "96990                       2.276711                              10.227451   \n",
      "133156                      0.127427                              11.878717   \n",
      "...                              ...                                    ...   \n",
      "129493                      0.070560                               9.494793   \n",
      "85410                       0.107336                              10.142522   \n",
      "239343                      1.591840                              11.748084   \n",
      "66571                       0.839788                               7.766415   \n",
      "352243                      0.123107                              10.469961   \n",
      "\n",
      "        cscRechitClusternXY  cscRechitClusternZ  cscRechitClusterXSpread  \\\n",
      "entry                                                                      \n",
      "135442                  239                 239                25.386328   \n",
      "311313                   58                  58                 5.881213   \n",
      "319843                  806                 806                24.275703   \n",
      "96990                   792                 792                24.045345   \n",
      "133156                  584                 584                35.844662   \n",
      "...                     ...                 ...                      ...   \n",
      "129493                   93                  93                12.268860   \n",
      "85410                   556                 556                19.354061   \n",
      "239343                   53                  53                19.580301   \n",
      "66571                   226                 226                47.179867   \n",
      "352243                  454                 454                30.473711   \n",
      "\n",
      "        cscRechitClusterYSpread  cscRechitClusterZSpread  ...  \\\n",
      "entry                                                     ...   \n",
      "135442                22.702909                64.058075  ...   \n",
      "311313                 9.671576                14.297481  ...   \n",
      "319843                34.783436                18.914974  ...   \n",
      "96990                 34.621517                44.333145  ...   \n",
      "133156                34.335625                98.424515  ...   \n",
      "...                         ...                      ...  ...   \n",
      "129493                 8.539155                12.052048  ...   \n",
      "85410                 14.649676                46.505459  ...   \n",
      "239343                31.193052                 0.033432  ...   \n",
      "66571                 23.411526                22.248463  ...   \n",
      "352243                28.771004                33.415508  ...   \n",
      "\n",
      "        cscRechitClusterDeltaRSpread  cscRechitClusterMajorAxis  \\\n",
      "entry                                                             \n",
      "135442                      0.152985                   0.132210   \n",
      "311313                      0.080073                   0.066876   \n",
      "319843                      0.097362                   0.074559   \n",
      "96990                       0.076419                   0.061567   \n",
      "133156                      0.150685                   0.137877   \n",
      "...                              ...                        ...   \n",
      "129493                      0.087298                   0.077831   \n",
      "85410                       0.073442                   0.058695   \n",
      "239343                      0.065583                   0.063278   \n",
      "66571                       0.137608                   0.120700   \n",
      "352243                      0.090099                   0.067784   \n",
      "\n",
      "        cscRechitClusterMinorAxis  cscRechitClusterSkewX  \\\n",
      "entry                                                      \n",
      "135442                   0.076973              -2.987662   \n",
      "311313                   0.044039              -4.691644   \n",
      "319843                   0.062613              -8.514921   \n",
      "96990                    0.045270              11.805981   \n",
      "133156                   0.060793              -9.423838   \n",
      "...                           ...                    ...   \n",
      "129493                   0.039539              -0.340713   \n",
      "85410                    0.044143              -4.243847   \n",
      "239343                   0.017233             -19.597956   \n",
      "66571                    0.066086              41.557011   \n",
      "352243                   0.059355               2.959071   \n",
      "\n",
      "        cscRechitClusterSkewY  cscRechitClusterSkewZ  cscRechitClusterKurtX  \\\n",
      "entry                                                                         \n",
      "135442             -18.326395            -163.560379               0.783149   \n",
      "311313              -4.214734              -5.004777              -0.138427   \n",
      "319843              11.141620              50.897434              -0.096327   \n",
      "96990               22.813150              90.904083              -0.164910   \n",
      "133156              -1.618452             194.955139              -0.397380   \n",
      "...                       ...                    ...                    ...   \n",
      "129493              -0.081475             -16.716562              -0.787059   \n",
      "85410               -1.757390               9.620709              -0.483234   \n",
      "239343              15.441490               0.006004               0.591429   \n",
      "66571               -1.603329             -62.425606               0.106642   \n",
      "352243             -14.174444            -131.724243              -0.720339   \n",
      "\n",
      "        cscRechitClusterKurtY  cscRechitClusterKurtZ  cscRechitClusterSize  \n",
      "entry                                                                       \n",
      "135442               3.566464              13.380309                   239  \n",
      "311313              -0.661569              -1.877458                    58  \n",
      "319843              -1.053756              15.082350                   806  \n",
      "96990               -0.465410               2.214775                   792  \n",
      "133156               0.553624               3.152221                   584  \n",
      "...                       ...                    ...                   ...  \n",
      "129493              -1.311593              -0.076102                    93  \n",
      "85410               -0.036870              -1.845970                   556  \n",
      "239343              -0.875622              -1.180793                    53  \n",
      "66571               -0.844762              11.654335                   226  \n",
      "352243               0.067816              18.087564                   454  \n",
      "\n",
      "[206446 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# see what training data looks like\n",
    "print(train_labels)\n",
    "print(train_data)\n",
    "\n",
    "# store number of features for input shape\n",
    "n_features = train_data.shape[1]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f236d0b7",
   "metadata": {},
   "source": [
    "# TODO: standard scalar. Fit on train_data and apply to test_data and val_data\n",
    "#It affects the results.\n",
    "scaler = StandardScaler()\n",
    "train_data = scaler.fit_transform(train_data)\n",
    "\n",
    "val_data = scaler.transform(val_data)\n",
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4745b13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the model and metrics\n",
    "METRICS = [\n",
    "      keras.metrics.MeanSquaredError(name='Brier score'),\n",
    "]\n",
    "\n",
    "\n",
    "def make_model(metrics=METRICS, output_bias=None, layers = [50, 30, 20, 5, 1], n_input = n_features, learningrate = 1e-3):\n",
    "    if output_bias is not None:\n",
    "        output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "    #initializer = tf.keras.initializers.RandomNormal(mean=0., stddev=1.)\n",
    "    #initializer = tf.keras.initializers.RandomUniform(minval=0., maxval=200, seed=None)\n",
    "    initializer = tf.keras.initializers.Constant(value=100)\n",
    "    \n",
    "    model = keras.Sequential(keras.layers.Dense(layers[0], activation = 'relu', input_shape = (n_input,)))\n",
    "\n",
    "    \n",
    "    for nodes in layers[1:]:\n",
    "        model.add(keras.layers.Dense(nodes, activation = 'relu'))\n",
    "    \n",
    "\n",
    "    model.compile(\n",
    "        optimizer = keras.optimizers.Adam(learning_rate = learningrate),\n",
    "        loss = keras.losses.MeanSquaredError(name='MSE'),\n",
    "        metrics = metrics\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65f0b95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prerequesites\n",
    "\n",
    "X_train, Y_train = sklearn.utils.shuffle(train_data, train_labels, random_state=0) # change to random_state=None for full randomness\n",
    "X_test, Y_test = sklearn.utils.shuffle(test_data, test_labels, random_state=0) # change to random_state=None for full randomness\n",
    "X_val, Y_val = sklearn.utils.shuffle(val_data, val_labels, random_state=0) # change to random_state=None for full randomness\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor = 'val_loss',\n",
    "    verbose = 1,\n",
    "    patience = 10,\n",
    "    mode = 'min',#max\n",
    "    restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [layers, LOFeatures, epochs, batchsize, learnrate, train_loss, val_loss, test_loss, history]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "testing_df = pd.DataFrame({'layers': [], 'LOFeatures': [],'epochs': [],'batchsize': [], 'learnrate': [], 'train_loss': [], 'val_loss': [], 'test_loss': [], 'history': []})\n",
    "print(testing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2588653",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    fig, ax = plt.subplots(figsize = (6, 4))\n",
    "    ax.plot(history.epoch, history.history['loss'], label = 'Training', color = 'blue')\n",
    "    ax.plot(history.epoch, history.history['val_loss'], linestyle = '--', color = 'blue', label = 'Validation')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_yscale('log')\n",
    "    ax.legend()\n",
    "    \n",
    "def predict_plot(model, test_data, test_labels, batches, title = None, axlabels = ('clusters', 'generated particle energy')):\n",
    "    fig, ax = plt.subplots(figsize = (6, 4))\n",
    "    \n",
    "    predictions = model.predict(test_data, batch_size = batches,  verbose=0)\n",
    "    histdata, bins, dummy = ax.hist(test_labels, bins = 50, histtype=\"step\", color = 'b', label = 'truth')\n",
    "    ax.hist(predictions, bins = bins, histtype=\"step\", color = 'r', label = 'predictions')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylabel(axlabels[0])\n",
    "    ax.set_xlabel(axlabels[1])\n",
    "    ax.legend()\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "\n",
    "        \n",
    "def modeltest(plotdatax, plotdatay, layers = [50, 30, 20, 5, 1], leftoutfeatures = [], epochs = 100, learn = 1e-3, batchsize = 1024):\n",
    "    print('model layers : ', layers, \n",
    "         '\\nfeatures left out : ', leftoutfeatures,\n",
    "         '\\nepochs : ', epochs,\n",
    "         '\\nbatch size : ', batchsize,\n",
    "         '\\nlearning rate : ', learn)\n",
    "    mymodel = make_model(layers = layers, learningrate = learn)\n",
    "    #mymodel.summary()\n",
    "    history = mymodel.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    batch_size = batchsize,\n",
    "    epochs = epochs, \n",
    "    callbacks = [early_stopping],\n",
    "    validation_data = (X_val, Y_val),\n",
    "    verbose = 0)\n",
    "    \n",
    "    \n",
    "    results = mymodel.evaluate(X_train, Y_train, batch_size = batchsize, verbose=0)\n",
    "    print(\"Loss on training: {:0.4f}\".format(results[0]))\n",
    "    \n",
    "    results_val = mymodel.evaluate(X_val, Y_val, batch_size = batchsize, verbose=0)\n",
    "    print(\"Loss on validation: {:0.4f}\".format(results_val[0]))\n",
    "    \n",
    "    results_test = mymodel.evaluate(X_test, Y_test, batch_size = batchsize, verbose=0)\n",
    "    print(\"Loss on test: {:0.4f}\".format(results_test[0]))\n",
    "    print(\"-----------------\")\n",
    "    \n",
    "    ep = eearly_stopping.stopped_epoch\n",
    "    if ep == 0:\n",
    "        ep = epochs\n",
    "        \n",
    "    new_row = {'layers': layers, 'LOFeatures': leftoutfeatures, 'epochs': ep, 'batchsize': batchsize, 'learnrate': learn, 'train_loss': results[0], 'val_loss': results_val[0], 'test_loss': results_test[0], 'history': history}\n",
    "    testing_df.loc[len(testing_df)] = new_row\n",
    "\n",
    "    \n",
    "    #plot_loss(history)\n",
    "    #predict_plot(model = mymodel,  test_data = test_data, test_labels = test_labels, title = 'predictions on test data', batches = batchsize)\n",
    "    #predict_plot(model = mymodel, test_data = train_data, test_labels = train_labels, title = 'predictions on training data', batches = batchsize)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85e7af2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model layers :  [50, 30, 20, 5, 1] \n",
      "features left out :  [] \n",
      "epochs :  100 \n",
      "batch size :  1024 \n",
      "learning rate :  0.1\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "Epoch 44: early stopping\n",
      "Loss on training: 5023.2773\n",
      "Loss on validation: 4929.1631\n",
      "Loss on test: 5174.1763\n",
      "-----------------\n",
      "model layers :  [50, 30, 20, 5, 1] \n",
      "features left out :  [] \n",
      "epochs :  100 \n",
      "batch size :  1024 \n",
      "learning rate :  0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/dust/cms/user/loewetob/anaconda3/envs/mds_regression/lib/python3.7/site-packages/pandas/core/dtypes/cast.py:881: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  element = np.asarray(element)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 11: early stopping\n",
      "Loss on training: 34028.9414\n",
      "Loss on validation: 33805.4414\n",
      "Loss on test: 34107.9336\n",
      "-----------------\n",
      "model layers :  [50, 30, 20, 5, 1] \n",
      "features left out :  [] \n",
      "epochs :  100 \n",
      "batch size :  1024 \n",
      "learning rate :  0.1\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 11: early stopping\n",
      "Loss on training: 34028.9414\n",
      "Loss on validation: 33805.4414\n",
      "Loss on test: 34107.9336\n",
      "-----------------\n",
      "model layers :  [50, 30, 20, 5, 1] \n",
      "features left out :  [] \n",
      "epochs :  100 \n",
      "batch size :  1024 \n",
      "learning rate :  0.01\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "Epoch 57: early stopping\n",
      "Loss on training: 4528.0933\n",
      "Loss on validation: 4505.8291\n",
      "Loss on test: 4713.4717\n",
      "-----------------\n",
      "model layers :  [50, 30, 20, 5, 1] \n",
      "features left out :  [] \n",
      "epochs :  100 \n",
      "batch size :  1024 \n",
      "learning rate :  0.01\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 11: early stopping\n",
      "Loss on training: 34028.9414\n",
      "Loss on validation: 33805.4414\n",
      "Loss on test: 34107.9336\n",
      "-----------------\n",
      "model layers :  [50, 30, 20, 5, 1] \n",
      "features left out :  [] \n",
      "epochs :  100 \n",
      "batch size :  1024 \n",
      "learning rate :  0.01\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "Epoch 40: early stopping\n",
      "Loss on training: 4608.3735\n",
      "Loss on validation: 4559.9707\n",
      "Loss on test: 4784.1372\n",
      "-----------------\n",
      "model layers :  [50, 30, 20, 5, 1] \n",
      "features left out :  [] \n",
      "epochs :  100 \n",
      "batch size :  1024 \n",
      "learning rate :  0.001\n",
      "Restoring model weights from the end of the best epoch: 84.\n",
      "Epoch 94: early stopping\n",
      "Loss on training: 4506.6094\n",
      "Loss on validation: 4495.4263\n",
      "Loss on test: 4706.9253\n",
      "-----------------\n",
      "model layers :  [50, 30, 20, 5, 1] \n",
      "features left out :  [] \n",
      "epochs :  100 \n",
      "batch size :  1024 \n",
      "learning rate :  0.001\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 11: early stopping\n",
      "Loss on training: 34028.9414\n",
      "Loss on validation: 33805.4414\n",
      "Loss on test: 34107.9336\n",
      "-----------------\n",
      "model layers :  [50, 30, 20, 5, 1] \n",
      "features left out :  [] \n",
      "epochs :  100 \n",
      "batch size :  1024 \n",
      "learning rate :  0.001\n",
      "Loss on training: 4487.5532\n",
      "Loss on validation: 4512.1572\n",
      "Loss on test: 4720.2285\n",
      "-----------------\n",
      "model layers :  [50, 30, 20, 5, 1] \n",
      "features left out :  [] \n",
      "epochs :  100 \n",
      "batch size :  1024 \n",
      "learning rate :  0.0001\n",
      "Loss on training: 4917.5054\n",
      "Loss on validation: 4870.7427\n",
      "Loss on test: 5071.8052\n",
      "-----------------\n",
      "model layers :  [50, 30, 20, 5, 1] \n",
      "features left out :  [] \n",
      "epochs :  100 \n",
      "batch size :  1024 \n",
      "learning rate :  0.0001\n",
      "Loss on training: 4870.7065\n",
      "Loss on validation: 4833.2217\n",
      "Loss on test: 5020.6831\n",
      "-----------------\n",
      "model layers :  [50, 30, 20, 5, 1] \n",
      "features left out :  [] \n",
      "epochs :  100 \n",
      "batch size :  1024 \n",
      "learning rate :  0.0001\n",
      "Loss on training: 4874.8491\n",
      "Loss on validation: 4828.5259\n",
      "Loss on test: 5021.5190\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "#test different learning rates\n",
    "lrate = 0.1\n",
    "while lrate > 0.00001:\n",
    "    for i in range(3):\n",
    "        modeltest(plotdatax = test_data, plotdatay = test_labels, layers = [50, 30, 20, 5, 1], learn = lrate, batchsize = 1024)\n",
    "    lrate = lrate / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layers</th>\n",
       "      <th>LOFeatures</th>\n",
       "      <th>epochs</th>\n",
       "      <th>batchsize</th>\n",
       "      <th>learnrate</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[50, 30, 20, 5, 1]</td>\n",
       "      <td>[]</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>5023.277344</td>\n",
       "      <td>4929.163086</td>\n",
       "      <td>5174.176270</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x2af627f59...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[50, 30, 20, 5, 1]</td>\n",
       "      <td>[]</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>34028.941406</td>\n",
       "      <td>33805.441406</td>\n",
       "      <td>34107.933594</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x2af73ecdf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[50, 30, 20, 5, 1]</td>\n",
       "      <td>[]</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>34028.941406</td>\n",
       "      <td>33805.441406</td>\n",
       "      <td>34107.933594</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x2af73f481...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[50, 30, 20, 5, 1]</td>\n",
       "      <td>[]</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>4528.093262</td>\n",
       "      <td>4505.829102</td>\n",
       "      <td>4713.471680</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x2af7cbfcb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[50, 30, 20, 5, 1]</td>\n",
       "      <td>[]</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>34028.941406</td>\n",
       "      <td>33805.441406</td>\n",
       "      <td>34107.933594</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x2af7a2ec5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[50, 30, 20, 5, 1]</td>\n",
       "      <td>[]</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>4608.373535</td>\n",
       "      <td>4559.970703</td>\n",
       "      <td>4784.137207</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x2af7a2f2f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[50, 30, 20, 5, 1]</td>\n",
       "      <td>[]</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>4506.609375</td>\n",
       "      <td>4495.426270</td>\n",
       "      <td>4706.925293</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x2af7a2ffb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[50, 30, 20, 5, 1]</td>\n",
       "      <td>[]</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>34028.941406</td>\n",
       "      <td>33805.441406</td>\n",
       "      <td>34107.933594</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x2af7a3075...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[50, 30, 20, 5, 1]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>4487.553223</td>\n",
       "      <td>4512.157227</td>\n",
       "      <td>4720.228516</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x2af7a6a34...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[50, 30, 20, 5, 1]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4917.505371</td>\n",
       "      <td>4870.742676</td>\n",
       "      <td>5071.805176</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x2af7a3137...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[50, 30, 20, 5, 1]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4870.706543</td>\n",
       "      <td>4833.221680</td>\n",
       "      <td>5020.683105</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x2af7a31e7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[50, 30, 20, 5, 1]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4874.849121</td>\n",
       "      <td>4828.525879</td>\n",
       "      <td>5021.519043</td>\n",
       "      <td>&lt;keras.callbacks.History object at 0x2af7cbfca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                layers LOFeatures  epochs  batchsize  learnrate    train_loss  \\\n",
       "0   [50, 30, 20, 5, 1]         []    43.0     1024.0     0.1000   5023.277344   \n",
       "1   [50, 30, 20, 5, 1]         []    10.0     1024.0     0.1000  34028.941406   \n",
       "2   [50, 30, 20, 5, 1]         []    10.0     1024.0     0.1000  34028.941406   \n",
       "3   [50, 30, 20, 5, 1]         []    56.0     1024.0     0.0100   4528.093262   \n",
       "4   [50, 30, 20, 5, 1]         []    10.0     1024.0     0.0100  34028.941406   \n",
       "5   [50, 30, 20, 5, 1]         []    39.0     1024.0     0.0100   4608.373535   \n",
       "6   [50, 30, 20, 5, 1]         []    93.0     1024.0     0.0010   4506.609375   \n",
       "7   [50, 30, 20, 5, 1]         []    10.0     1024.0     0.0010  34028.941406   \n",
       "8   [50, 30, 20, 5, 1]         []     0.0     1024.0     0.0010   4487.553223   \n",
       "9   [50, 30, 20, 5, 1]         []     0.0     1024.0     0.0001   4917.505371   \n",
       "10  [50, 30, 20, 5, 1]         []     0.0     1024.0     0.0001   4870.706543   \n",
       "11  [50, 30, 20, 5, 1]         []     0.0     1024.0     0.0001   4874.849121   \n",
       "\n",
       "        val_loss     test_loss  \\\n",
       "0    4929.163086   5174.176270   \n",
       "1   33805.441406  34107.933594   \n",
       "2   33805.441406  34107.933594   \n",
       "3    4505.829102   4713.471680   \n",
       "4   33805.441406  34107.933594   \n",
       "5    4559.970703   4784.137207   \n",
       "6    4495.426270   4706.925293   \n",
       "7   33805.441406  34107.933594   \n",
       "8    4512.157227   4720.228516   \n",
       "9    4870.742676   5071.805176   \n",
       "10   4833.221680   5020.683105   \n",
       "11   4828.525879   5021.519043   \n",
       "\n",
       "                                              history  \n",
       "0   <keras.callbacks.History object at 0x2af627f59...  \n",
       "1   <keras.callbacks.History object at 0x2af73ecdf...  \n",
       "2   <keras.callbacks.History object at 0x2af73f481...  \n",
       "3   <keras.callbacks.History object at 0x2af7cbfcb...  \n",
       "4   <keras.callbacks.History object at 0x2af7a2ec5...  \n",
       "5   <keras.callbacks.History object at 0x2af7a2f2f...  \n",
       "6   <keras.callbacks.History object at 0x2af7a2ffb...  \n",
       "7   <keras.callbacks.History object at 0x2af7a3075...  \n",
       "8   <keras.callbacks.History object at 0x2af7a6a34...  \n",
       "9   <keras.callbacks.History object at 0x2af7a3137...  \n",
       "10  <keras.callbacks.History object at 0x2af7a31e7...  \n",
       "11  <keras.callbacks.History object at 0x2af7cbfca...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest = testing_df[testing_df['learnrate'] == 0.01]['train_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b70f62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4528.09326171875\n"
     ]
    }
   ],
   "source": [
    "print(dftest.array[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mds_regression",
   "language": "python",
   "name": "mds_regression"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
